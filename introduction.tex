\section*{Introduction}
This report documents my $6$ months internship as a research student at Kyushu University. I worked in the Sakamoto laboratory under the supervision of eponymous professor Sakamoto, part of the faculty of design on Ohashi campus in Fukuoka, Japan.

The subject of my research was the identification of animation character from color images, an image classification problem in which we consider images of characters from Japanese animation. The automated analysis of animation images is not a well studied field, although there are a few research papers in Japanese. The goal was therefore to improve on this state of the art, with the envisioned application domain being the automated annotation of images in web artist communities such as Pixiv\footnote{
\url{www.pixiv.net} is a popular Japanese web artist community.
} or deviantArt\footnote{
\url{www.deviantart.com} is a popular English speaking web artist community.
}. One of the expected milestones was the presentation of our work at the JCEEE Kyushu International Sessions in Kumamoto at the end of September.

Our solution to the animation character identification problem takes the shape of a computer vision system with preprocessing, segmentation and classification of images. A number of methods were considered for each of these steps, with a strong focus on classification. In this document, we present each of the algorithms considered, their underlying theoretical foundations, as well as their implementation in practice and we analyse their performance against a dataset of animation images.

Our methods for classification start by considering a graph structure from the set of segments obtained from the previous segmentation step. We first studied graph kernels inspired from works in string matching for the purposes of classifying the graphs as developed by Harchaoui and Bach \cite{harchaoui2007image}. Failing to capture the global features of the graph in an efficient manner, we then turned to methods from spectral graph theory to classify our segmentation graphs, borrowing from works by Wilson \cite{harchaoui2007image}
\cite{wilson2005pattern} and inspired by developments in spectral methods for clustering \cite{ng2002spectral}, segmentation \cite{shi2000normalized} and dimensionality reduction \cite{roweis2000nonlinear} \cite{belkin2003laplacian}. Graph Laplacians did not capture enough information about the images, so we finally turned to a segment matching method based on a fuzzy control system and a simple algorithm to determine one-to-one relationships between segments of $2$ images. This method is computationally efficient, and gives good results on our dataset, measuring a recognition rate of $59$\% using leave one out cross validation.

In this document, we also consider future extensions to solve the shortcomings of our method. Notably, our method fails to properly distinguish characters sharing similar color schemes. To solve this issue, we propose a semi-supervised embedding method to determine a non-linear color space ideally clustering the training data based on literature for non-linear dimensionality reduction \cite{roweis2000nonlinear} \cite{belkin2003laplacian} and classification \cite{urahama2007semi}. Furthermore we suggest that, although failing to properly characterize the images on their own, segmentation graphs could help distinguish these characters sharing similar color palettes. We also introduce some possible research directions for the purpose of background extraction.
